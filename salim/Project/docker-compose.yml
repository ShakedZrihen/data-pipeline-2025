services:
  # S3 Simulator (LocalStack)
  s3:
    container_name: s3-simulator
    image: gresau/localstack-persist:4
    ports:
      - "4566:4566"
    environment:
      - SERVICES=s3
      - DEBUG=1
      - S3_SKIP_SIGNATURE_VALIDATION=1
      - AWS_DEFAULT_REGION=us-east-1
    volumes:
      - "localstack-data:/persisted-data"
      - "./init-s3.py:/etc/localstack/init/ready.d/init-s3.py"
    networks:
      - pipeline-network
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:4566/_localstack/health"]
      interval: 30s
      timeout: 10s
      retries: 5

  # RabbitMQ
  rabbitmq:
    container_name: rabbitmq-server
    image: rabbitmq:3-management
    ports:
      - "5672:5672"   # AMQP port
      - "15672:15672" # Management UI port
    environment:
      - RABBITMQ_DEFAULT_USER=admin
      - RABBITMQ_DEFAULT_PASS=admin
    volumes:
      - rabbitmq-data:/var/lib/rabbitmq
    networks:
      - pipeline-network
    healthcheck:
      test: ["CMD", "rabbitmq-diagnostics", "ping"]
      interval: 30s
      timeout: 10s
      retries: 5

  # PostgreSQL Database (for enricher)
  postgres:
    container_name: postgres-db
    image: postgres:15
    environment:
      - POSTGRES_DB=postgres
      - POSTGRES_USER=postgres
      - POSTGRES_PASSWORD=${POSTGRES_PASSWORD:-8HeXmxYnvy5xu}
    ports:
      - "5432:5432"
    volumes:
      - postgres-data:/var/lib/postgresql/data
    networks:
      - pipeline-network
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U postgres"]
      interval: 30s
      timeout: 10s
      retries: 5

  # Crawler Service
  crawler:
    build: ./crawler
    container_name: crawler-service
    depends_on:
      s3:
        condition: service_healthy
    environment:
      - AWS_ACCESS_KEY_ID=test
      - AWS_SECRET_ACCESS_KEY=test
      - AWS_DEFAULT_REGION=us-east-1
      - S3_ENDPOINT=http://s3:4566
    volumes:
      - "./crawler:/app"
      - "/tmp:/tmp"
    networks:
      - pipeline-network
    command: sh -c "Xvfb :99 -screen 0 1024x768x24 & python run.py"

  # Extractor Service
  extractor:
    build: ./extractor
    container_name: extractor-service
    depends_on:
      s3:
        condition: service_healthy
      rabbitmq:
        condition: service_healthy
    environment:
      - AWS_ACCESS_KEY_ID=test
      - AWS_SECRET_ACCESS_KEY=test
      - AWS_DEFAULT_REGION=us-east-1
      - S3_ENDPOINT=http://s3:4566
      - RABBITMQ_HOST=rabbitmq
      - RABBITMQ_PORT=5672
      - RABBITMQ_USERNAME=admin
      - RABBITMQ_PASSWORD=admin
    volumes:
      - "./extractor:/app"
      - "./extractor/extracted_files:/app/extracted_files"
    networks:
      - pipeline-network
    command: python extractor.py --latest

  # Enricher Service
  enricher:
    build: ./enricher
    container_name: enricher-service
    depends_on:
      postgres:
        condition: service_healthy
      rabbitmq:
        condition: service_healthy
    environment:
      - DATABASE_URL=${DATABASE_URL:-postgresql://postgres:${POSTGRES_PASSWORD:-8HeXmxYnvy5xu}@postgres:5432/postgres}
      - SUPABASE_URL=${SUPABASE_URL:-https://sifzchhpypeprqfirrdb.supabase.co}
      - SUPABASE_KEY=${SUPABASE_KEY}
      - RABBITMQ_HOST=rabbitmq
      - RABBITMQ_PORT=5672
      - RABBITMQ_USERNAME=admin
      - RABBITMQ_PASSWORD=admin
      - PRICEFULL_QUEUE=pricefull_queue
      - PROMOFULL_QUEUE=promofull_queue
      - DLQ_QUEUE=dead_letter_queue
      - BATCH_SIZE=10
      - CLAUDE_API_KEY=${CLAUDE_API_KEY}
      - LOG_LEVEL=INFO
    volumes:
      - "./enricher:/app"
      - "./enricher/Stores:/app/Stores"
    networks:
      - pipeline-network
    command: sh -c "python create_tables.py && python load_stores.py && python queue_consumer.py"

  # API Service (Node.js)
  api:
    build: ../api
    container_name: api-service
    ports:
      - "3001:3001"
    depends_on:
      postgres:
        condition: service_healthy
    environment:
      - DATABASE_URL=${DATABASE_URL:-postgresql://postgres:${POSTGRES_PASSWORD:-8HeXmxYnvy5xu}@postgres:5432/postgres}
      - SUPABASE_URL=${SUPABASE_URL:-https://sifzchhpypeprqfirrdb.supabase.co}
      - SUPABASE_KEY=${SUPABASE_KEY}
      - RABBITMQ_HOST=rabbitmq
      - RABBITMQ_PORT=5672
      - RABBITMQ_USERNAME=admin
      - RABBITMQ_PASSWORD=admin
      - INPUT_QUEUE=all_data_queue
      - DLQ_QUEUE=dead_letter_queue
      - BATCH_SIZE=10
      - CLAUDE_API_KEY=${CLAUDE_API_KEY}
      - LOG_LEVEL=INFO
    volumes:
      - "../api:/app"
      - "/app/node_modules"
    networks:
      - pipeline-network
    command: npm start

networks:
  pipeline-network:
    driver: bridge

volumes:
  localstack-data:
  rabbitmq-data:
  postgres-data:
